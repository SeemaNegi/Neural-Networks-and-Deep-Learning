# Neural-Networks-and-Deep-Learning
This repo contains the solved optional and graded assignments of the course 'Neural Networks and Deep Learning'
by deeplearning.ai. 
There are 3 folders named as  Week 2, Week 3 and Week 4.
Week 2 contains 2 notebooks:-
In notebook (Python_Basics_With_Numpy_v3a.ipynb) we will:

- Learn how to use numpy.

- Implement some basic core deep learning functions such as the softmax, sigmoid, dsigmoid, etc...

- Learn how to handle data by normalizing inputs and reshaping images.

- Recognize the importance of vectorization.

- Understand how python broadcasting works.

By completing the notebook Logistic_Regression_with_a_Neural_Network_mindset_v6a we will:

- Work with logistic regression in a way that builds intuition relevant to neural networks.

- Learn how to minimize the cost function.

- Understand how derivatives of the cost are used to update parameters.

Week 3 folder contains 1 notebook (Planar_data_classification_with_onehidden_layer_v6c.ipynb).
By completing this notebook we will:

- Develop an intuition of back-propagation and see it work on data.

- Recognize that the more hidden layers we have the more complex structure we could capture.

- Build all the helper functions to implement a full model with one hidden layer.

Week 4 folder consists of 2 notebooks. By completing "Building your Deep Neural Network -Step by Step" assignment we will:

- Develop an intuition of the over all structure of a neural network.

- Write functions (e.g. forward propagation, backward propagation, logistic loss, etc...) that would help us decompose our code and ease the process of building a neural network.

- Initialize/update parameters according to our desired structure.

By completing "Deep Neural Network Application Image Classification" assignment, we will:

- Learn how to use all the helper functions we built in the previous assignment to build a model of any structure we want.

- Experiment with different model architectures and see how each one behaves.

- Recognize that it is always easier to build our helper functions before attempting to build a neural network from scratch.





